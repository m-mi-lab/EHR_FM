# EHR_FM Pipeline Configuration
# Copy this file to .env and fill in your values
# All variables can be overridden via CLI: VAR=value ./run_pipeline.sh

# ==============================================================================
# PHYSIONET CREDENTIALS (Required for data download)
# ==============================================================================

# PhysioNet username (your registered email)
PHYSIONET_USERNAME=

# PhysioNet password
PHYSIONET_PASSWORD=

# ==============================================================================
# DATA PATHS
# ==============================================================================

# Raw MIMIC-IV data directory (contains hosp/ and icu/ subdirectories)
MIMICIV_RAW_DIR=./data/mimic-iv-raw

# Pre-MEDS intermediate output directory
MIMICIV_PRE_MEDS_DIR=./data/mimic-iv-pre-meds

# MEDS ETL output directory (will contain data/train and data/test)
MIMICIV_MEDS_DIR=./data/mimic-iv-meds

# Tokenization output directory
TOKENIZED_DIR=./data/tokenized

# ==============================================================================
# MLFLOW CONFIGURATION (Required for remote tracking)
# ==============================================================================

# Remote MLflow tracking server URL
MLFLOW_TRACKING_URI=

# MLflow experiment name (default: EHR_FM)
MLFLOW_EXPERIMENT_NAME=EHR_FM

# MLflow authentication (optional, leave empty if not required)
MLFLOW_TRACKING_USERNAME=
MLFLOW_TRACKING_PASSWORD=

# Alternative: Token-based authentication
# MLFLOW_TRACKING_TOKEN=

# S3-compatible artifact storage (e.g., Tigris, MinIO, AWS S3)
# Set this to your S3-compatible endpoint URL
MLFLOW_S3_ENDPOINT_URL=

# Artifact URI for storing checkpoints (s3://bucket-name/path)
MLFLOW_ARTIFACT_URI=

# ==============================================================================
# PIPELINE OPTIONS
# ==============================================================================

# Number of parallel workers for MEDS ETL (adjust based on CPU cores)
N_WORKERS=4

# Whether to unzip .csv.gz files before ETL (true/false)
DO_UNZIP=false

# ==============================================================================
# TRAINING CONFIGURATION
# ==============================================================================

# Model configuration
# Options: gpt2_small_4exp, gpt2_small_8exp, gpt2_small_monolith, gpt2_tiny
MODEL_CONFIG=gpt2_small_4exp

# Training configuration
# Options: default, 4_exp, 8_exp, tiny
TRAIN_CONFIG=4_exp

# Number of GPUs to use (auto = detect available GPUs, or specify number)
WORLD_SIZE=auto

# ==============================================================================
# ADVANCED OPTIONS
# ==============================================================================

# Validation split fraction for training
VAL_SPLIT_FRACTION=0.05

# Resume training from checkpoint (leave empty to start fresh)
RESUME_CHECKPOINT=

